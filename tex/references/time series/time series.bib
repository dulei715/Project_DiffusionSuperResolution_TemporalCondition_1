
@misc{ho_denoising_2020,
	title = {Denoising {Diffusion} {Probabilistic} {Models}},
	url = {http://arxiv.org/abs/2006.11239},
	doi = {10.48550/arXiv.2006.11239},
	abstract = {We present high quality image synthesis results using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. Our best results are obtained by training on a weighted variational bound designed according to a novel connection between diffusion probabilistic models and denoising score matching with Langevin dynamics, and our models naturally admit a progressive lossy decompression scheme that can be interpreted as a generalization of autoregressive decoding. On the unconditional CIFAR10 dataset, we obtain an Inception score of 9.46 and a state-of-the-art FID score of 3.17. On 256x256 LSUN, we obtain sample quality similar to ProgressiveGAN. Our implementation is available at https://github.com/hojonathanho/diffusion.},
	language = {en},
	urldate = {2025-07-21},
	publisher = {arXiv},
	author = {Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
	month = dec,
	year = {2020},
	note = {arXiv:2006.11239 [cs]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {PDF:files/69/Ho 等 - 2020 - Denoising Diffusion Probabilistic Models.pdf:application/pdf},
}

@article{li_diffusion-based_2025,
	title = {{DIFFUSION}-{BASED} {DECOUPLED} {DETERMINISTIC} {AND} {UNCERTAIN} {FRAMEWORK} {FOR} {PROBABILISTIC} {MUL}- {TIVARIATE} {TIME} {SERIES} {FORECASTING}},
	abstract = {Diffusion-based denoising models have demonstrated impressive performance in probabilistic forecasting for multivariate time series (MTS). Nonetheless, existing approaches often model the entire data distribution, neglecting the variability in uncertainty across different components of the time series. This paper introduces a Diffusion-based Decoupled Deterministic and Uncertain (D3U) framework for probabilistic MTS forecasting. The framework integrates non-probabilistic forecasting with conditional diffusion generation, enabling both accurate point predictions and probabilistic forecasting. D3U utilizes a point forecasting model to nonprobabilistically model high-certainty components in the time series, generating embedded representations that are conditionally injected into a diffusion model. To better model high-uncertainty components, a patch-based denoising network (PatchDN) is designed in the conditional diffusion model. Designed as a plug-andplay framework, D3U can be seamlessly integrated into existing point forecasting models to provide probabilistic forecasting capabilities. It can also be applied to other conditional diffusion methods that incorporate point forecasting models. Experiments on six real-world datasets demonstrate that our method achieves over a 20\% improvement in both point and probabilistic forecasting performance in MTS long-term forecasting compared to state-of-the-art (SOTA) probabilistic forecasting methods. Additionally, extensive ablation studies further validate the effectiveness of the D3U framework.},
	language = {en},
	author = {Li, Qi and Zhang, Zhenyu and Yao, Lei and Li, Zhaoxia and Zhong, Tianyi and Zhang, Yong},
	year = {2025},
	file = {PDF:files/70/Li 等 - 2025 - DIFFUSION-BASED DECOUPLED DETERMINISTIC AND UNCERTAIN FRAMEWORK FOR PROBABILISTIC MUL- TIVARIATE TIM.pdf:application/pdf},
}

@article{yang_difftst_2025,
	title = {{DiffTST}: {Diff} {Transformer} for {Multivariate} {Time} {Series} {Forecast}},
	volume = {13},
	copyright = {https://creativecommons.org/licenses/by/4.0/legalcode},
	issn = {2169-3536},
	shorttitle = {{DiffTST}},
	url = {https://ieeexplore.ieee.org/document/10972038/},
	doi = {10.1109/access.2025.3563070},
	abstract = {Deep learning models employing the Transformer architecture have demonstrated exceptional performance in the field of multivariate time series forecasting research. However, these models often incorporate irrelevant or weakly relevant information during the processing of time series, leading to noise. This phenomenon diverts the attention mechanism from crucial features within the time series, thereby impacting the overall forecasting performance. To mitigate this issue, our study introduces DiffTST, which employs a Differential Transformer to enhance the model’s focus on relevant context within the time series, thereby mitigating the influence of noise on forecasting accuracy. The model utilizes independent channels to process time series data, ensuring that each input token contains information from a single channel exclusively. Furthermore, each channel is segmented into multiple patches to facilitate the extraction of local information. Subsequently, the Differential Transformer module is employed to process the sequence features of these patches, alleviating the tendency of Transformer-based models to allocate excessive attention to irrelevant sequence information. Ultimately, the forecast outcomes are derived through a MultiLayer Perceptron. Our findings indicate that DiffTST achieves higher or comparable long-term forecasting accuracy compared to the current state-of-the-art Transformer-based models. On the main datasets (Weather, Traffic, Electricity), our method reduces MSE by 0.008, 0.087, and 0.023 and MAE by 0.004, 0.069, and 0.025 compared to PatchTST.},
	language = {en},
	urldate = {2025-07-21},
	journal = {IEEE Access},
	author = {Yang, Song and Han, Wenyong and Wan, Yaping and Zhu, Tao and Liu, Zhiming and Li, Shuangjian},
	year = {2025},
	note = {Publisher: Institute of Electrical and Electronics Engineers (IEEE)},
	pages = {73671--73679},
	file = {PDF:files/71/Yang 等 - 2025 - DiffTST Diff Transformer for Multivariate Time Series Forecast.pdf:application/pdf},
}

@article{song_deep_2024,
	title = {Deep learning-based time series forecasting},
	volume = {58},
	copyright = {https://creativecommons.org/licenses/by-nc-nd/4.0},
	issn = {1573-7462},
	url = {https://link.springer.com/10.1007/s10462-024-10989-8},
	doi = {10.1007/s10462-024-10989-8},
	abstract = {With the advancement of deep learning algorithms and the growing availability of computational power, deep learning-based forecasting methods have gained significant importance in the domain of time series forecasting. In the past decade, there has been a rapid rise in time series forecasting approaches. This paper comprehensively reviews the advancements in deep learning-based forecasting models spanning 2014 to 2024. We provide a comprehensive examination of the capabilities of these models in capturing correlations among time steps and time series variables. Additionally, we explore methods to enhance the efficiency of long-term time series forecasting and summarize the diverse loss functions employed in these models. Moreover, this study systematically evaluates the effectiveness of these approaches in both univariate and multivariate time series forecasting tasks across diverse domains. We comprehensively discuss the strengths and limitations of various algorithms from multiple perspectives, analyze their capacity to capture different types of time series information, including trend and season patterns, and compare methods for enhancing the computational efficiency of these models. Finally, we summarize the experimental results and discuss the future directions in time series forecasting. Codes and datasets are available at https://github.com/TCCofWANG/ Deep-Learning-based-Time-Series-Forecasting.},
	language = {en},
	number = {1},
	urldate = {2025-07-21},
	journal = {Artificial Intelligence Review},
	author = {Song, Xiaobao and Deng, Liwei and Wang, Hao and Zhang, Yaoan and He, Yuxin and Cao, Wenming},
	month = nov,
	year = {2024},
	note = {Publisher: Springer Science and Business Media LLC},
	file = {PDF:files/73/Song 等 - 2024 - Deep learning-based time series forecasting.pdf:application/pdf},
}

@article{shen_multi-resolution_2024,
	title = {{MULTI}-{RESOLUTION} {DIFFUSION} {MODELS} {FOR} {TIME} {SERIES} {FORECASTING}},
	abstract = {The diffusion model has been successfully used in many computer vision applications, such as text-guided image generation and image-to-image translation. Recently, there have been attempts on extending the diffusion model for time series data. However, these extensions are fairly straightforward and do not utilize the unique properties of time series data. As different patterns are usually exhibited at multiple scales of a time series, we in this paper leverage this multi-resolution temporal structure and propose the multi-resolution diffusion model (mr-Diff). By using the seasonal-trend decomposition, we sequentially extract fine-to-coarse trends from the time series for forward diffusion. The denoising process then proceeds in an easy-to-hard non-autoregressive manner. The coarsest trend is generated first. Finer details are progressively added, using the predicted coarser trends as condition variables. Experimental results on nine real-world time series datasets demonstrate that mr-Diff outperforms state-of-the-art time series diffusion models. It is also better than or comparable across a wide variety of advanced time series prediction models.},
	language = {en},
	author = {Shen, Lifeng and Chen, Weiyu and Kwok, James T},
	year = {2024},
	file = {PDF:files/77/Shen 等 - 2024 - MULTI-RESOLUTION DIFFUSION MODELS FOR TIME SERIES FORECASTING.pdf:application/pdf},
}

@article{naiman_utilizing_nodate,
	title = {Utilizing {Image} {Transforms} and {Diffusion} {Models} for {Generative} {Modeling} of {Short} and {Long} {Time} {Series}},
	abstract = {Lately, there has been a surge in interest surrounding generative modeling of time series data. Most existing approaches are designed either to process short sequences or to handle long-range sequences. This dichotomy can be attributed to gradient issues with recurrent networks, computational costs associated with transformers, and limited expressiveness of state space models. Towards a unified generative model for varying-length time series, we propose in this work to transform sequences into images. By employing invertible transforms such as the delay embedding and the short-time Fourier transform, we unlock three main advantages: i) We can exploit advanced diffusion vision models; ii) We can remarkably process short- and long-range inputs within the same framework; and iii) We can harness recent and established tools proposed in the time series to image literature. We validate the effectiveness of our method through a comprehensive evaluation across multiple tasks, including unconditional generation, interpolation, and extrapolation. We show that our approach achieves consistently state-of-the-art results against strong baselines. In the unconditional generation tasks, we show remarkable mean improvements of 58.17\% over previous diffusion models in the short discriminative score and 132.61\% in the (ultra-)long classification scores. Code is at https://github.com/azencot-group/ImagenTime.},
	language = {en},
	author = {Naiman, Ilan and Berman, Nimrod},
	file = {PDF:files/79/Naiman和Berman - Utilizing Image Transforms and Diffusion Models for Generative Modeling of Short and Long Time Serie.pdf:application/pdf},
}

@article{feng_latent_2024,
	title = {Latent {Diffusion} {Transformer} for {Probabilistic} {Time} {Series} {Forecasting}},
	volume = {38},
	issn = {2374-3468, 2159-5399},
	url = {https://ojs.aaai.org/index.php/AAAI/article/view/29085},
	doi = {10.1609/aaai.v38i11.29085},
	abstract = {The probability prediction of multivariate time series is a notoriously challenging but practical task. This research proposes to condense high-dimensional multivariate time series forecasting into a problem of latent space time series generation, to improve the expressiveness of each timestamp and make forecasting more manageable. To solve the problem that the existing work is hard to extend to highdimensional multivariate time series, we present a latent multivariate time series diffusion framework called Latent Diffusion Transformer (LDT), which consists of a symmetric statistics-aware autoencoder and a diffusion-based conditional generator, to implement this idea. Through careful design, the time series autoencoder can compress multivariate timestamp patterns into a concise latent representation by considering dynamic statistics. Then, the diffusion-based conditional generator is able to efficiently generate realistic multivariate timestamp values on a continuous latent space under a novel self-conditioning guidance which is modeled in a non-autoregressive way. Extensive experiments demonstrate that our model achieves state-of-the-art performance on many popular high-dimensional multivariate time series datasets.},
	language = {en},
	number = {11},
	urldate = {2025-07-21},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	author = {Feng, Shibo and Miao, Chunyan and Zhang, Zhong and Zhao, Peilin},
	month = mar,
	year = {2024},
	note = {Publisher: Association for the Advancement of Artificial Intelligence (AAAI)},
	pages = {11979--11987},
	file = {PDF:files/83/Feng 等 - 2024 - Latent Diffusion Transformer for Probabilistic Time Series Forecasting.pdf:application/pdf},
}
